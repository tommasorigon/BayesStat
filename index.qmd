---
title: "Bayesian Statistics"
subtitle: "Ph.D. in Economics, Statistics, and Data Science - University of Milano-Bicocca"
author:
  name: Raffaele Argiento, Bernardo Nipoti, and Tommaso Rigon
  affiliation: DEMS
page-layout: full
format:
  html:
    html-math-method: katex
    echo: true
    callout-appearance: minimal
    theme: [simplex, template.css]
    toc: true
    embed-resources: false
    code-line-numbers: true
    smooth-scroll: true
    fig-dpi: 250
---

## Detailed syllabus

Bayesian Statistics is a Ph.D. course organized in **three modules**

#### Principles of Bayesian statistics (Bernardo Nipoti, 15h)

-	Exchangeability and de Finettiâ€™s theorem
-	The Bayesian framework
-	Conjugate prior distributions
-	Bayesian point estimation
-	Test and credible intervals
-	The normal model
-	The multivariate normal model
-	Introduction to hierarchical modelling

---------------------------------------------------

#### [Bayesian computations](https://tommasorigon.github.io/CompStat/) (Tommaso Rigon, 15h)

- Metropolis-Hastings and Gibbs sampling 
- Optimal scaling & adaptive Metropolis 
- MALA algorithm & Hamiltonian Monte Carlo 
- Missing data problems, Gibbs sampling and the EM algorithm 
- Laplace appr., Variational Bayes, and Expectation Propagation

---------------------------------------------------

#### [Mixture models in Bayesian Statistics](http://www.raffaeleargiento.it/syllabus_bayesiana_bicocca_2023.pdf) (Raffaele Argiento, 12h)

- Finite and infinite mixture models, the basic concepts of kernel, mixing measure and components of a mixture.
- The latent component allocation variables and the clustering it induces on the data by a mixture model. Difference between component and cluster.
- The prior on the parameter "cluster" induced by the mixing measure: the exchangeable product partition function (EPPF) and its properties. The prior on the number of components and the prior on the number of clusters.
- Linear and non-linear functionals of the posterior distributions and how to approximate them via Markov Chain Monte Carlo (MCMC) algorithms.
- Marginal and conditional algorithms for mixture model, the Chinese restaurant process and its generalization.

## Exam

The exam rules are described [here](exam_rules.pdf). In short, you will be asked to read a paper, write a short review, and then make a presentation. Here is an example from previous years:

1. [Paper](AOAP2018.pdf) assigned to a PhD student, using the keyword system;
1. [Short review](ghilotti_review.pdf), written using the *Bayesian Analysis* template;
1. [Slides](ghilotti_slides.pdf) of the presentation.

## References

#### Books

 - Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A. and Rubin, D.B., 2013. [_Bayesian data analysis_](http://www.stat.columbia.edu/~gelman/book/BDA3.pdf). CRC press.
 - Hoff, P. D. (2009). _A First Course in Bayesian Statistical Methods_. Springer.
 - Robert, C. P., and Casella, G. (2009). [_Introducing Monte Carlo methods with R_](https://link.springer.com/content/pdf/10.1007%2F978-1-4419-1576-4.pdf). Springer.
 -	Robert, C., 2007. _The Bayesian choice: from decision-theoretic foundations to computational implementation_. Springer Science & Business Media.

 

#### Articles

Additional references are available online on the instructors' websites.


------------------------------------------------

